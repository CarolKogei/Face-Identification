{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification using Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lando_norris_folder = r\"dataset\\Lando Norris\"\n",
    "other_drivers_folder = r\"dataset/Other Drivers\"\n",
    "clean_data_Lando = r\"clean data\\Lando Norris\"\n",
    "clean_data_Other = r\"clean data/Other Drivers\"\n",
    "\n",
    "def detect_and_crop_faces(input_folder, output_folder):\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # load cascade for face detection\n",
    "    for filename in os.listdir(input_folder):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                face = img[y:y+h, x:x+w]\n",
    "                resized_face = cv2.resize(face, (160, 160))  # Resize to Facenet input size\n",
    "                output_path = os.path.join(output_folder, f\"{filename.split('.')[0]}_{i}.jpg\")\n",
    "                cv2.imwrite(output_path, resized_face)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect faces from norris and other drivers\n",
    "\n",
    "detect_and_crop_faces(lando_norris_folder, clean_data_Lando)\n",
    "detect_and_crop_faces(other_drivers_folder, clean_data_Other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and pre-processing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialize empty list for data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# function to load and pre-process data\n",
    "def load_images(folder, label):\n",
    "    for filename in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, filename) # path to an individual image\n",
    "        image = cv2.imread(image_path) # read image\n",
    "        image = cv2.resize(image, (100, 100)) # resize image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "\n",
    "        # append image data and label\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "# load data for both classes (Lando Norris and Other Drivers)\n",
    "load_images(clean_data_Lando, 0) # label \"0\" for Lando Norris\n",
    "load_images(clean_data_Other, 1) # label \"1\" for Other Drivers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train test data into 80/20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the cnn model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4992 - accuracy: 0.4167 - val_loss: 420.6503 - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 416.1649 - accuracy: 0.5833 - val_loss: 202.0863 - val_accuracy: 0.5714\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 197.2183 - accuracy: 0.5833 - val_loss: 11.2036 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 6.4525 - accuracy: 0.6250 - val_loss: 98.6112 - val_accuracy: 0.4286\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 92.9735 - accuracy: 0.4167 - val_loss: 81.3257 - val_accuracy: 0.4286\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 77.7612 - accuracy: 0.4167 - val_loss: 45.4599 - val_accuracy: 0.4286\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 43.1350 - accuracy: 0.4167 - val_loss: 18.5327 - val_accuracy: 0.4286\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 16.2726 - accuracy: 0.4167 - val_loss: 1.5520 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2801 - accuracy: 0.8333 - val_loss: 15.4431 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 12.9647 - accuracy: 0.5833 - val_loss: 5.7519 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c0cc0f110>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "cnn_model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 8.9871 - accuracy: 0.3750\n",
      "Test Accuracy: 37.50%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction: Lando Norris\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "def predict_image(model, image_path, img_size=(100, 100)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #img = img.flatten()\n",
    "    img = img / 255.0 # normalize pixel values\n",
    "    img = np.expand_dims(img, axis=-1) #channel dimension for grayscale\n",
    "    img = np.expand_dims(img, axis=0) # adds batch dimension\n",
    "\n",
    "\n",
    "    prediction = cnn_model.predict(img)\n",
    "    return \"Lando Norris\" if prediction < 0.5 else \"Other Drivers\"\n",
    "\n",
    "result = predict_image(cnn_model, r\"clean data\\Lando Norris\\20_0.jpg\")\n",
    "print(f\"Prediction: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceIdEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
